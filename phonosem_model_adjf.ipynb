{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Звуко-слово. Прилагательное, 9 букв, именительный падеж, единственное число"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T08:32:54.013739Z",
     "start_time": "2019-03-07T08:32:51.507339Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Bidirectional, Dropout, Dense, TimeDistributed, Input, Embedding, Flatten, Add, Reshape, Concatenate, Lambda, Activation\n",
    "from keras.models import Model\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "import MySQLdb\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "DROPOUT = 0.1\n",
    "UNITS = 128\n",
    "WORD_SET = ' -абвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "SOUND_WORD_SET = ' аеёиоуыэюяа\\'е\\'ё\\'и\\'о\\'у\\'ы\\'э\\'ю\\'я\\'бб\\'вв\\'гг\\'дд\\'жзз\\'йкк\\'лл\\'мм\\'нн\\'пп\\'рр\\'сс\\'тт\\'фф\\'хх\\'цчшщ'\n",
    "WORD_MAX_LENGTH = 30\n",
    "STRESS_SOUDNS = ('а\\'','е\\'','и\\'','о\\'','у\\'','ы\\'','э\\'','ю\\'','я\\'')\n",
    "SOUND_WORD_MAX_LENGTH = 30\n",
    "PHONOSEM_VALUES_LEN = 25\n",
    "\n",
    "WORD_LENGTH = 9\n",
    "\n",
    "WORD_DIC = {k: v for v, k in enumerate(WORD_SET)}\n",
    "SOUND_WORD_DIC = {k: i for i, k in enumerate(re.findall('[\\sа-яё]\\'?', SOUND_WORD_SET))}\n",
    "VOCAB_LEN = len(WORD_DIC)\n",
    "SOUND_VOCAB_LEN = len(SOUND_WORD_DIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-07T08:32:51.507Z"
    }
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-07T08:32:51.517Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/interlark/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: context interface will be changed.  Use explicit conn.commit() or conn.rollback().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "db_conn = MySQLdb.Connect(host='localhost', user='root', passwd='toPanta24', db='words_dataset', use_unicode=True,\n",
    "                                  charset=\"utf8\")\n",
    "#x_words = []\n",
    "x_sound_words = []\n",
    "x_stresses = []\n",
    "x_phonosem_values = []\n",
    "\n",
    "with db_conn as db_curr:\n",
    "    db_curr.execute('select distinct rnd_id, sound_word, primary_stress, type_id, value from words_rnd inner join phonosemantics on phonosemantics.word_id = words_rnd.id inner join morphemes on morphemes.word_id = words_rnd.id where secondary_stress IS NULL and char_length(word)=%d and not convert(word using \\'CP1251\\') regexp \\'[ьъ]\\' and morphemes.pos = \\'ADJF\\' and morphemes.case = \\'nomn\\' and morphemes.number=\\'sing\\' order by rnd_id' % (WORD_LENGTH,))\n",
    "    row = db_curr.fetchmany(PHONOSEM_VALUES_LEN)\n",
    "    while row:\n",
    "        phonosem_values = np.zeros(PHONOSEM_VALUES_LEN)\n",
    "        stresses = np.zeros(WORD_MAX_LENGTH)\n",
    "        for (rnd_id, sound_word, primary_stress, type_id, phonosem_value) in row:\n",
    "            phonosem_values[type_id - 1] = phonosem_value / 6\n",
    "        stresses[primary_stress] = 1\n",
    "#         if secondary_stress:\n",
    "#             stresses[secondary_stress] = 1\n",
    "        #x_words.append(word)\n",
    "        x_sound_words.append(sound_word)\n",
    "        x_stresses.append(stresses)\n",
    "        x_phonosem_values.append(phonosem_values)\n",
    "        row = db_curr.fetchmany(PHONOSEM_VALUES_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-07T08:32:51.520Z"
    }
   },
   "outputs": [],
   "source": [
    "def char_to_1_hot_tensor(char):\n",
    "    char_id = WORD_DIC[char]\n",
    "    hot_vec = np.zeros((VOCAB_LEN))\n",
    "    hot_vec[char_id] = 1.\n",
    "    return hot_vec\n",
    "\n",
    "def word_to_1_hot_tensors(word):\n",
    "    hot_vec = np.zeros((WORD_MAX_LENGTH, VOCAB_LEN))\n",
    "    for i, char in enumerate(word):\n",
    "        hot_vec[i,:] = char_to_1_hot_tensor(char)\n",
    "    return hot_vec\n",
    "\n",
    "def words_to_1_hot_tensors(words):\n",
    "    hot_vec = []\n",
    "    for word in words:\n",
    "        hot_vec.append(word_to_1_hot_tensors(word))\n",
    "    return np.array(hot_vec)\n",
    "\n",
    "##############################################################\n",
    "\n",
    "def sound_char_to_1_hot_tensor(sound_char):\n",
    "    sound_char_id = SOUND_WORD_DIC[sound_char]\n",
    "    hot_vec = np.zeros((SOUND_VOCAB_LEN))\n",
    "    hot_vec[sound_char_id] = 1.\n",
    "    return hot_vec\n",
    "\n",
    "def sound_word_to_1_hot_tensors(sound_word, max_length=SOUND_WORD_MAX_LENGTH):\n",
    "    hot_vec = np.zeros((max_length, SOUND_VOCAB_LEN))\n",
    "    for i, sound_char in enumerate(re.findall('[\\sа-яё]\\'?', sound_word)):\n",
    "        hot_vec[i,:] = sound_char_to_1_hot_tensor(sound_char)\n",
    "    return hot_vec\n",
    "\n",
    "def sound_words_to_1_hot_tensors(sound_words, max_length, p=None):\n",
    "    hot_vec = []\n",
    "    for sound_word in sound_words:\n",
    "        hot_vec.append(sound_word_to_1_hot_tensors(sound_word, max_length))\n",
    "    hot_vec = np.array(hot_vec)\n",
    "    if p==None:\n",
    "        return hot_vec\n",
    "    \n",
    "    p_vec = []\n",
    "    for j in range(len(hot_vec)):\n",
    "         p_vec.append(hot_vec[j][p])\n",
    "    return np.array(p_vec)\n",
    "\n",
    "\n",
    "def first_sound_char_tensor_to_sound_char(sound_char_tensor):\n",
    "    first_char_idx = np.argmax(sound_char_tensor)\n",
    "    for c, i in SOUND_WORD_DIC.items():\n",
    "        if i == first_char_idx:\n",
    "            return c\n",
    "        \n",
    "def sound_words_tensor_to_sound_chars(sound_char_tensor):\n",
    "    sound_chars_dic = {}\n",
    "    for c, i in SOUND_WORD_DIC.items():\n",
    "        sound_chars_dic[c] = sound_char_tensor[i]\n",
    "    return sorted(sound_chars_dic.items(), key=lambda kv: kv[1])\n",
    "\n",
    "##############################################################\n",
    "\n",
    "def get_first_value(values):\n",
    "    np_values = np.array(values)\n",
    "    return np_values[:,0] # first value of phonosemantics\n",
    "\n",
    "def sound_word_to_stress_char_idx(sound_word, stress):\n",
    "    stress_idx = np.where(stress==1)[0][0]\n",
    "    stressed_char = sound_word[stress_idx]\n",
    "    return SOUND_WORD_DIC[stressed_char]\n",
    "    \n",
    "def sound_word_to_first_char_idx(sound_word):\n",
    "    sound_chars = re.findall('[\\sа-яё]\\'?', sound_word)\n",
    "    return SOUND_WORD_DIC[sound_chars[0]]\n",
    "    \n",
    "def sound_word_to_first_char_tensor(sound_word):\n",
    "    tensor = np.zeros(SOUND_VOCAB_LEN)\n",
    "    tensor[sound_word_to_first_char_idx(sound_word)] = 1\n",
    "    return tensor\n",
    "\n",
    "def sound_word_to_stress_char_tensor(sound_word, stress):\n",
    "    tensor = np.zeros(SOUND_VOCAB_LEN)\n",
    "    tensor[sound_word_to_stress_char_idx(sound_word, stress)] = 1\n",
    "    return tensor\n",
    "\n",
    "def get_sound_words_first_chars_tensors(sound_words):\n",
    "    tensors = []\n",
    "    for sound_word in sound_words:\n",
    "        tensors.append(sound_word_to_first_char_tensor(sound_word))\n",
    "    return np.array(tensors)\n",
    "\n",
    "def get_sound_words_stress_chars_tensors(sound_words, stresses):\n",
    "    tensors = []\n",
    "    for i in range(len(sound_words)):\n",
    "        tensors.append(sound_word_to_stress_char_tensor(sound_words[i], stresses[i]))\n",
    "    return np.array(tensors)\n",
    "\n",
    "def get_sound_word_to_stress_char_tensor(sound_word):\n",
    "    tensor = np.zeros(SOUND_VOCAB_LEN)\n",
    "    sound_chars = re.findall('[\\sа-яё]\\'?', sound_word)\n",
    "    for sound_char in sound_chars:\n",
    "        if sound_char in STRESS_SOUDNS:\n",
    "            tensor[SOUND_WORD_DIC[sound_char]] = 1\n",
    "    return tensor\n",
    "\n",
    "def get_sound_words_to_stress_char_tensors(sound_words):\n",
    "    tensors = []\n",
    "    for sound_word in sound_words:\n",
    "        tensors.append(get_sound_word_to_stress_char_tensor(sound_word))\n",
    "    return np.array(tensors)\n",
    "\n",
    "##############################################################\n",
    "\n",
    "def sound_word_delete_first_and_stress(sound_word):\n",
    "    new_sound_word = []\n",
    "    sound_chars = re.findall('[\\sа-яё]\\'?', sound_word)\n",
    "    for sound_char in range(1, len(sound_chars)):\n",
    "        if sound_char not in STRESS_SOUDNS:\n",
    "            new_sound_word.append(sound_char)\n",
    "    return new_sound_word\n",
    "\n",
    "def sound_word_to_vocab_freq_tensor(sound_word):\n",
    "    sound_word = sound_word_delete_first_and_stress(sound_word)\n",
    "    vocab = np.zeros(SOUND_VOCAB_LEN)\n",
    "    for c, i in SOUND_WORD_DIC.items():\n",
    "        vocab[i] = sound_word.count(c)\n",
    "    return vocab\n",
    "\n",
    "def sound_words_to_vocab_freq_tensors(sound_words):\n",
    "    tensors = []\n",
    "    for sound_word in sound_words:\n",
    "        tensors.append(sound_word_to_vocab_freq_tensor(sound_word))\n",
    "    return np.array(tensors)\n",
    "\n",
    "##############################################################\n",
    "\n",
    "def sound_word_to_vocab_part_freq_tensor(sound_word):\n",
    "    vocab = np.zeros(SOUND_VOCAB_LEN)\n",
    "    for c, i in SOUND_WORD_DIC.items():\n",
    "        vocab[i] = sound_word.count(c)/len(sound_word)\n",
    "    return vocab\n",
    "\n",
    "def sound_words_to_vocab_part_freq_tensors(sound_words):\n",
    "    tensors = []\n",
    "    for sound_word in sound_words:\n",
    "        tensors.append(sound_word_to_vocab_part_freq_tensor(sound_word))\n",
    "    return np.array(tensors)\n",
    "\n",
    "\n",
    "def sound_char_tensor_to_sound_char(sound_char_tensor):\n",
    "    sound_char_idx = np.argmax(sound_char_tensor)\n",
    "    for c, i in SOUND_WORD_DIC.items():\n",
    "        if i==sound_char_idx:\n",
    "            return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-07T08:32:51.525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phomosem shape: (8002, 25)\n"
     ]
    }
   ],
   "source": [
    "x_p = np.array(x_phonosem_values)\n",
    "\n",
    "y_0 = sound_words_to_1_hot_tensors(x_sound_words, WORD_LENGTH,0)\n",
    "y_1 = sound_words_to_1_hot_tensors(x_sound_words, WORD_LENGTH,1)\n",
    "y_2 = sound_words_to_1_hot_tensors(x_sound_words, WORD_LENGTH,2)\n",
    "y_3 = sound_words_to_1_hot_tensors(x_sound_words, WORD_LENGTH,3)\n",
    "y_4 = sound_words_to_1_hot_tensors(x_sound_words, WORD_LENGTH,4)\n",
    "y_5 = sound_words_to_1_hot_tensors(x_sound_words, WORD_LENGTH,5)\n",
    "y_6 = sound_words_to_1_hot_tensors(x_sound_words, WORD_LENGTH,6)\n",
    "y_7 = sound_words_to_1_hot_tensors(x_sound_words, WORD_LENGTH,7)\n",
    "y_8 = sound_words_to_1_hot_tensors(x_sound_words, WORD_LENGTH,8)\n",
    "\n",
    "\n",
    "print('phomosem shape:', x_p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-07T08:32:51.528Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 25)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 2560)          66560       input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2560)          6556160     dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 2560)          6556160     dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2560)          6556160     dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 2560)          6556160     dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 2560)          6556160     dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 2560)          6556160     dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 2560)          6556160     dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 2560)          6556160     dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 2560)          6556160     dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 2560)          6556160     dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 1024)          2622464     dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 1024)          1049600     dense_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 1024)          1049600     dense_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 1024)          1049600     dense_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 1024)          1049600     dense_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_19 (Dense)                 (None, 1024)          1049600     dense_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_21 (Dense)                 (None, 1024)          1049600     dense_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_22 (Dense)                 (None, 1024)          1049600     dense_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_24 (Dense)                 (None, 1024)          1049600     dense_22[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_25 (Dense)                 (None, 1024)          1049600     dense_24[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_27 (Dense)                 (None, 1024)          1049600     dense_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_28 (Dense)                 (None, 1024)          1049600     dense_27[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_30 (Dense)                 (None, 1024)          1049600     dense_28[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_31 (Dense)                 (None, 1024)          1049600     dense_30[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_33 (Dense)                 (None, 1024)          1049600     dense_31[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_34 (Dense)                 (None, 1024)          1049600     dense_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_36 (Dense)                 (None, 1024)          1049600     dense_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_37 (Dense)                 (None, 1024)          1049600     dense_36[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 57)            58425       dense_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 57)            58425       dense_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_20 (Dense)                 (None, 57)            58425       dense_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_23 (Dense)                 (None, 57)            58425       dense_22[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_26 (Dense)                 (None, 57)            58425       dense_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_29 (Dense)                 (None, 57)            58425       dense_28[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_32 (Dense)                 (None, 57)            58425       dense_31[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_35 (Dense)                 (None, 57)            58425       dense_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_38 (Dense)                 (None, 57)            58425       dense_37[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 86,619,649\n",
      "Trainable params: 86,619,649\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input((PHONOSEM_VALUES_LEN,))\n",
    "x = Dense(2560)(input)\n",
    "for i in range(10):\n",
    "    x = Dense(2560)(x)\n",
    "\n",
    "p = 2\n",
    "hp = 1024\n",
    "output = []\n",
    "\n",
    "for w in range(WORD_LENGTH):\n",
    "    for i in range(p):\n",
    "        x = Dense(hp)(x)\n",
    "    output_x = Dense(SOUND_VOCAB_LEN)(x)\n",
    "    output.append(output_x)\n",
    "\n",
    "model = Model(inputs=input, outputs=output)\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0)\n",
    "model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T06:07:31.775162Z",
     "start_time": "2019-03-03T06:07:31.755047Z"
    }
   },
   "source": [
    "## Тренировка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-07T08:32:51.530Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0318 21:14:59.792827 140507994244928 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:601: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc98b1d4f28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val, y_0_train, y_0_val, y_1_train, y_1_val, y_2_train, y_2_val, y_3_train, y_3_val, y_4_train, y_4_val, y_5_train, y_5_val, y_6_train, y_6_val, y_7_train, y_7_val, y_8_train, y_8_val = train_test_split(x_p, y_0, y_1, y_2, y_3, y_4, y_5, y_6, y_7, y_8, test_size=0.10, random_state=1)\n",
    "\n",
    "model.fit(x_train, [y_0_train, y_1_train, y_2_train, y_3_train, y_4_train, y_5_train, y_6_train, y_7_train, y_8_train], verbose=0, epochs=500, validation_data=(x_val, [y_0_val, y_1_val, y_2_val, y_3_val, y_4_val, y_5_val, y_6_val, y_7_val, y_8_val]), batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-07T08:32:51.533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: [array([0.43937333, 0.39482667, 0.53562333, 0.59477167, 0.53691667,\n",
      "       0.44590833, 0.39348833, 0.402895  , 0.48006   , 0.49689   ,\n",
      "       0.45056667, 0.51067167, 0.49299833, 0.47493833, 0.51727167,\n",
      "       0.40991833, 0.47905667, 0.45886167, 0.43612667, 0.46582833,\n",
      "       0.5405    , 0.41077833, 0.46115833, 0.36687333, 0.48788167])]\n",
      ">> в\n",
      ">> а\n",
      ">> ч\n",
      ">> т\n",
      ">> ё'\n",
      ">> х\n",
      ">> н\n",
      ">> а\n",
      ">> я\n"
     ]
    }
   ],
   "source": [
    "val = [x_p[55]]\n",
    "\n",
    "p = model.predict(np.array(val))\n",
    "\n",
    "print('value:', val)\n",
    "\n",
    "for i in range(WORD_LENGTH):\n",
    "    print('>>',sound_char_tensor_to_sound_char(p[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./current_adjf_9_scaled.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0318 23:11:54.250297 140677512243008 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:601: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./current_adjf_9_scaled.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_sound_word(sound_chars_tensor):\n",
    "    for i in range(len(sound_chars_tensor)):\n",
    "        print(sound_char_tensor_to_sound_char(sound_chars_tensor[i]), end='')\n",
    "    print()\n",
    "    \n",
    "def generate_phonetics():\n",
    "    ret = np.random.rand(PHONOSEM_VALUES_LEN)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Плохое прилагательное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: [array([0.99      , 0.36503459, 0.74253885, 0.8532546 , 0.79126841,\n",
      "       0.63011117, 0.62784541, 0.7330594 , 0.36323942, 0.13561595,\n",
      "       0.56336333, 0.72990685, 0.1318455 , 0.45312354, 0.09374759,\n",
      "       0.53301645, 0.51584652, 0.76485056, 0.71417195, 0.31599311,\n",
      "       0.34913228, 0.96644598, 0.80190428, 0.8368579 , 0.42206441])]\n",
      "к'од'су'к'т'ый\n"
     ]
    }
   ],
   "source": [
    "phonetics = generate_phonetics()\n",
    "phonetics[0] = 0.99\n",
    "val = [ phonetics ]\n",
    "print('value:', val)\n",
    "sound_word = model.predict(np.array(val))\n",
    "print_sound_word(sound_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Доброе прилагательное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: [array([0.55289766, 0.28153077, 0.86213694, 0.75548432, 0.75718696,\n",
      "       0.5001844 , 0.91437327, 0.39326511, 0.6808949 , 0.82507183,\n",
      "       0.82368871, 0.37707912, 0.59247035, 0.7176963 , 0.3525429 ,\n",
      "       0.82208437, 0.53211653, 0.60457011, 0.64346872, 0.36681275,\n",
      "       0.39868039, 0.82482807, 0.01      , 0.66749165, 0.40922422])]\n",
      "згю'в'у'п'ный\n"
     ]
    }
   ],
   "source": [
    "phonetics = generate_phonetics()\n",
    "phonetics[22] = 0.01\n",
    "val = [ phonetics ]\n",
    "print('value:', val)\n",
    "sound_word = model.predict(np.array(val))\n",
    "print_sound_word(sound_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
